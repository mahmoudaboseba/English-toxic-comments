{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers.recurrent import LSTM, GRU,SimpleRNN\nfrom keras.layers.core import Dense, Activation, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom keras.preprocessing import sequence, text\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import EarlyStopping ,ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:09.966331Z","iopub.execute_input":"2022-06-03T12:27:09.967016Z","iopub.status.idle":"2022-06-03T12:27:13.158249Z","shell.execute_reply.started":"2022-06-03T12:27:09.966941Z","shell.execute_reply":"2022-06-03T12:27:13.157414Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:13.806294Z","iopub.execute_input":"2022-06-03T12:27:13.806998Z","iopub.status.idle":"2022-06-03T12:27:15.904877Z","shell.execute_reply.started":"2022-06-03T12:27:13.806966Z","shell.execute_reply":"2022-06-03T12:27:15.903984Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:15.906423Z","iopub.execute_input":"2022-06-03T12:27:15.907043Z","iopub.status.idle":"2022-06-03T12:27:15.926393Z","shell.execute_reply.started":"2022-06-03T12:27:15.907012Z","shell.execute_reply":"2022-06-03T12:27:15.925649Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = train.loc[:40000,:]\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:17.574200Z","iopub.execute_input":"2022-06-03T12:27:17.574961Z","iopub.status.idle":"2022-06-03T12:27:17.582448Z","shell.execute_reply.started":"2022-06-03T12:27:17.574926Z","shell.execute_reply":"2022-06-03T12:27:17.581623Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(40001, 3)"},"metadata":{}}]},{"cell_type":"code","source":"train['comment_text'].apply(lambda x:len(str(x).split())).max()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:19.383336Z","iopub.execute_input":"2022-06-03T12:27:19.384138Z","iopub.status.idle":"2022-06-03T12:27:19.579092Z","shell.execute_reply.started":"2022-06-03T12:27:19.384098Z","shell.execute_reply":"2022-06-03T12:27:19.578244Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1403"},"metadata":{}}]},{"cell_type":"code","source":"xtrain, xvalid, ytrain, yvalid = train_test_split(train.comment_text.values, train.toxic.values, \n                                                  stratify=train.toxic.values, \n                                                  random_state=42, \n                                                  test_size=0.2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:21.286349Z","iopub.execute_input":"2022-06-03T12:27:21.287031Z","iopub.status.idle":"2022-06-03T12:27:21.310513Z","shell.execute_reply.started":"2022-06-03T12:27:21.286994Z","shell.execute_reply":"2022-06-03T12:27:21.309761Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nimport re\nimport string\nstop_words = stopwords.words('english')\n\nimport unicodedata\n\ndef remove_non_ascii(text):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n\ndef to_lowercase(text):\n    return text.lower()\n\ndef remove_punctuation(text):\n    translator = str.maketrans('', '', string.punctuation)\n    return text.translate(translator)\n\ndef replace_numbers(text):\n    return re.sub(r'\\d+', '', text)\n\ndef remove_whitespaces(text):\n    return text.strip()\n\ndef remove_stopwords(words, stop_words):\n    return [word for word in words if word not in stop_words]\n\ndef stem_words(words):\n    stemmer = PorterStemmer()\n    return [stemmer.stem(word) for word in words]\n\ndef lemmatize_words(words):\n    lemmatizer = WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in words]\n\ndef lemmatize_verbs(words):\n    lemmatizer = WordNetLemmatizer()\n    return ' '.join([lemmatizer.lemmatize(word, pos='v') for word in words])\n\ndef text2words(text):\n  return word_tokenize(text)\n\ndef normalize_text( text):\n    text = remove_non_ascii(text)\n    text = remove_punctuation(text)\n    text = to_lowercase(text)\n    text = replace_numbers(text)\n    words = text2words(text)\n    words = remove_stopwords(words, stop_words)\n    words = lemmatize_words(words)\n    words = lemmatize_verbs(words)\n    return ''.join(words)\ndef normalize_corpus(corpus):\n  return [normalize_text(t) for t in corpus]","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:22.803347Z","iopub.execute_input":"2022-06-03T12:27:22.804189Z","iopub.status.idle":"2022-06-03T12:27:23.495057Z","shell.execute_reply.started":"2022-06-03T12:27:22.804149Z","shell.execute_reply":"2022-06-03T12:27:23.493620Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"xtrain = normalize_corpus(xtrain)\nxvalid = normalize_corpus(xvalid)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:27:24.744703Z","iopub.execute_input":"2022-06-03T12:27:24.745066Z","iopub.status.idle":"2022-06-03T12:28:09.011687Z","shell.execute_reply.started":"2022-06-03T12:27:24.745036Z","shell.execute_reply":"2022-06-03T12:28:09.010824Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"early = EarlyStopping(monitor='val_loss', mode='min', patience=4) \nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\ncallbacks_list = [early, learning_rate_reduction]","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:28:09.013872Z","iopub.execute_input":"2022-06-03T12:28:09.014256Z","iopub.status.idle":"2022-06-03T12:28:09.019697Z","shell.execute_reply.started":"2022-06-03T12:28:09.014202Z","shell.execute_reply":"2022-06-03T12:28:09.018299Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"token = text.Tokenizer(num_words=None)\nmax_len = 1500\n\ntoken.fit_on_texts(list(xtrain) + list(xvalid))\nxtrain_seq = token.texts_to_sequences(xtrain)\nxvalid_seq = token.texts_to_sequences(xvalid)\n\n#zero pad the sequences\nxtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\nxvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n\nword_index = token.word_index","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:28:09.021064Z","iopub.execute_input":"2022-06-03T12:28:09.021637Z","iopub.status.idle":"2022-06-03T12:28:11.596863Z","shell.execute_reply.started":"2022-06-03T12:28:09.021598Z","shell.execute_reply":"2022-06-03T12:28:11.596027Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n# to save the fitted tokenizer\nwith open('tokenizer_version2_1.pickle', 'wb') as handle:\n    pickle.dump(token, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:28:11.598818Z","iopub.execute_input":"2022-06-03T12:28:11.599191Z","iopub.status.idle":"2022-06-03T12:28:11.694153Z","shell.execute_reply.started":"2022-06-03T12:28:11.599157Z","shell.execute_reply":"2022-06-03T12:28:11.693304Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(len(word_index) + 1,\n                 300,\n                 input_length=max_len))\nmodel.add(SimpleRNN(100))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(xtrain_pad, ytrain,validation_split = 0.2, epochs=10, batch_size=64,callbacks=callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(xvalid_pad, yvalid)\nprint(\"Auc: \" , accuracy*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_model = []\nscores_model.append({'Model': 'SimpleRNN','AUC_Score': accuracy})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\nf = open('../input/glove840b300dtxt/glove.840B.300d.txt','r',encoding='utf-8')\nfor line in tqdm(f):\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.asarray([float(val) for val in values[1:]])\n    embeddings_index[word] = coefs\nf.close()\nprint('Found %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:28:11.695678Z","iopub.execute_input":"2022-06-03T12:28:11.696083Z","iopub.status.idle":"2022-06-03T12:32:39.486470Z","shell.execute_reply.started":"2022-06-03T12:28:11.696036Z","shell.execute_reply":"2022-06-03T12:32:39.485602Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2196018it [04:27, 8200.91it/s]","output_type":"stream"},{"name":"stdout","text":"Found 2196017 word vectors.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_matrix = np.zeros((len(word_index) + 1, 300))\nfor word, i in tqdm(word_index.items()):\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:32:39.487877Z","iopub.execute_input":"2022-06-03T12:32:39.488711Z","iopub.status.idle":"2022-06-03T12:32:39.753693Z","shell.execute_reply.started":"2022-06-03T12:32:39.488671Z","shell.execute_reply":"2022-06-03T12:32:39.752512Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 79080/79080 [00:00<00:00, 311296.28it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"model_LSTM = Sequential()\nmodel_LSTM.add(Embedding(len(word_index) + 1,\n                 300,\n                 weights=[embedding_matrix],\n                 input_length=max_len,\n                 trainable=False))\n\nmodel_LSTM.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\nmodel_LSTM.add(Dense(1, activation='sigmoid'))\nmodel_LSTM.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n\nmodel_LSTM.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_LSTM.fit(xtrain_pad, ytrain,validation_split = 0.2, epochs=10, batch_size=64,callbacks=callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model_LSTM.evaluate(xvalid_pad, yvalid)\nprint(\"Auc: \" , accuracy*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_model.append({'Model': 'LSTM','AUC_Score': accuracy})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_GRU = Sequential()\nmodel_GRU.add(Embedding(len(word_index) + 1,\n             300,\n             weights=[embedding_matrix],\n             input_length=max_len,\n             trainable=False))\nmodel_GRU.add(SpatialDropout1D(0.3))\nmodel_GRU.add(GRU(300))\nmodel_GRU.add(Dense(1, activation='sigmoid'))\n\nmodel_GRU.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n    \nmodel_GRU.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_GRU.fit(xtrain_pad, ytrain,validation_split = 0.2, epochs=10, batch_size=64,callbacks=callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model_GRU.evaluate(xvalid_pad, yvalid)\nprint(\"Auc: \" , accuracy*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores_model.append({'Model': 'GRU','AUC_Score': accuracy})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('./englishToxicModelRNN_version2.h5')\n#model_LSTM.save('./englishToxicModelLSTM_version2.h5')\nmodel_GRU.save('./englishToxicModelGRUVersion2.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint ,ReduceLROnPlateau ,EarlyStopping\nearly = EarlyStopping(monitor='val_loss', mode='min', patience=4) \nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\ncallbacks_list = [early, learning_rate_reduction]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_BI = Sequential()\nmodel_BI.add(Embedding(len(word_index) + 1,\n                 300,\n                 weights=[embedding_matrix],\n                 input_length=max_len,\n                 trainable=False))\nmodel_BI.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n\nmodel_BI.add(Dense(1,activation='sigmoid'))\nmodel_BI.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n    \n    \nmodel_BI.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:32:39.755060Z","iopub.execute_input":"2022-06-03T12:32:39.755609Z","iopub.status.idle":"2022-06-03T12:32:43.133445Z","shell.execute_reply.started":"2022-06-03T12:32:39.755570Z","shell.execute_reply":"2022-06-03T12:32:43.132534Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2022-06-03 12:32:39.852233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:39.934267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:39.935003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:39.937561: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-06-03 12:32:39.937867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:39.938610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:39.939326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:41.957616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:41.958542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:41.959378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-06-03 12:32:41.960805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-06-03 12:32:42.462041: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 94897200 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 1500, 300)         23724300  \n_________________________________________________________________\nbidirectional (Bidirectional (None, 600)               1442400   \n_________________________________________________________________\ndense (Dense)                (None, 1)                 601       \n=================================================================\nTotal params: 25,167,301\nTrainable params: 1,443,001\nNon-trainable params: 23,724,300\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_BI.fit(xtrain_pad, ytrain,batch_size = 32,\n                            validation_split=0.2,\n                                    verbose=1,\n                            epochs=5,\n                                    callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T12:33:17.908022Z","iopub.execute_input":"2022-06-03T12:33:17.908483Z","iopub.status.idle":"2022-06-03T19:35:44.609931Z","shell.execute_reply.started":"2022-06-03T12:33:17.908449Z","shell.execute_reply":"2022-06-03T19:35:44.609161Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"2022-06-03 12:33:17.915285: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 153600000 exceeds 10% of free system memory.\n2022-06-03 12:33:18.076427: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n800/800 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.9420","output_type":"stream"},{"name":"stderr","text":"2022-06-03 13:56:42.825575: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 38400000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"800/800 [==============================] - 5192s 6s/step - loss: 0.1648 - accuracy: 0.9420 - val_loss: 0.1187 - val_accuracy: 0.9550\nEpoch 2/5\n800/800 [==============================] - 5073s 6s/step - loss: 0.1222 - accuracy: 0.9550 - val_loss: 0.1132 - val_accuracy: 0.9572\nEpoch 3/5\n800/800 [==============================] - 5024s 6s/step - loss: 0.1076 - accuracy: 0.9604 - val_loss: 0.1049 - val_accuracy: 0.9606\nEpoch 4/5\n800/800 [==============================] - 4995s 6s/step - loss: 0.1167 - accuracy: 0.9574 - val_loss: 0.1616 - val_accuracy: 0.9427\nEpoch 5/5\n800/800 [==============================] - 5008s 6s/step - loss: 0.1040 - accuracy: 0.9617 - val_loss: 0.1084 - val_accuracy: 0.9586\n\nEpoch 00005: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f490c7d7b50>"},"metadata":{}}]},{"cell_type":"code","source":"model_BI.save('./englishToxicModelBI_version2.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-03T19:35:44.611863Z","iopub.execute_input":"2022-06-03T19:35:44.612289Z","iopub.status.idle":"2022-06-03T19:35:44.939107Z","shell.execute_reply.started":"2022-06-03T19:35:44.612250Z","shell.execute_reply":"2022-06-03T19:35:44.938274Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"2022-06-03 19:35:44.656853: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 94897200 exceeds 10% of free system memory.\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model_BI.evaluate(xvalid_pad, yvalid)\nprint(\"Auc: \" , accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-06-03T19:35:44.940467Z","iopub.execute_input":"2022-06-03T19:35:44.940805Z","iopub.status.idle":"2022-06-03T19:39:39.738747Z","shell.execute_reply.started":"2022-06-03T19:35:44.940778Z","shell.execute_reply":"2022-06-03T19:39:39.737546Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2022-06-03 19:35:44.943488: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 48006000 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"251/251 [==============================] - 235s 933ms/step - loss: 0.1134 - accuracy: 0.9560\nAuc:  0.9560055136680603\n","output_type":"stream"}]}]}